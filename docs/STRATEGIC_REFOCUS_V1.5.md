# üöÄ STRATEGIC REFOCUS: Universal AI Chat Hub (v1.5)

**Date:** January 26, 2026  
**Status:** üîÑ ACTIVE - Major Refactoring in Progress  
**Impact:** High - Strategic Product Pivot

---

## üì¢ IMPORTANT: New Direction

Private Chat Hub is undergoing a **major strategic refocus** from an Ollama-focused client to a **universal AI chat platform** supporting:

1. ‚úÖ **Local Models** (On-Device LiteRT/Gemini Nano) - Already implemented
2. ‚úÖ **Self-Hosted Models** (Ollama) - Already implemented
3. üÜï **Cloud APIs** (OpenAI, Anthropic, Google AI) - **NEW in v1.5**

**Key Change:** We are moving from "privacy-only" to "**privacy by choice**" - users can select their preferred balance of privacy, performance, and cost.

---

## üéØ New Product Vision

### Before (v1.0)
> "Private, self-hosted AI chat client for Ollama"

### After (v1.5+)
> "**Universal AI chat hub** - one app for all your AI models (local, self-hosted, cloud)"

---

## üìã What Agents Need to Know

### 1. **All Future Work Must Support This Vision**

When implementing features, consider:
- Will this work with **all provider types** (local, Ollama, cloud APIs)?
- Does the UI clearly distinguish between provider types?
- Are costs tracked for cloud APIs?
- Does fallback logic make sense?

### 2. **Provider Abstraction is Key**

All LLM interactions must go through the `LLMProvider` interface:
```dart
abstract class LLMProvider {
  String get providerId;
  ProviderType get type;  // LOCAL, SELF_HOSTED, CLOUD_API
  Stream<ChatResponse> sendMessage(...);
  Future<ProviderHealth> checkHealth();
}
```

### 3. **Three-Tier Architecture**

```
User
  ‚Üì
ChatService (Router)
  ‚Üì
LLMProvider (Abstract Interface)
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Local   ‚îÇ Ollama   ‚îÇ Cloud APIs   ‚îÇ
‚îÇ (Free)  ‚îÇ (Free)   ‚îÇ (Pay-per-use)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4. **Cost Awareness is Critical**

- Track token usage for **all cloud API messages**
- Display estimated costs clearly in UI
- Warn users approaching cost limits
- Suggest free alternatives (local/Ollama) when appropriate

### 5. **Smart Fallback Chains**

When a provider fails:
```
Cloud API fails ‚Üí Try Ollama ‚Üí Try Local ‚Üí Queue
Ollama fails ‚Üí Try Cloud (if user allows) ‚Üí Try Local ‚Üí Queue
Local fails ‚Üí Try Ollama ‚Üí Try Cloud (if user allows)
```

---

## üìÅ Key Documentation (Updated)

### Start Here
1. **[PRODUCT_VISION.md](PRODUCT_VISION.md)** - Complete vision and strategy (UPDATED)
2. **[PRODUCT_REQUIREMENTS_V1.5.md](PRODUCT_REQUIREMENTS_V1.5.md)** - v1.5 requirements (NEW)
3. **[ARCHITECTURE_CLOUD_API_INTEGRATION.md](ARCHITECTURE_CLOUD_API_INTEGRATION.md)** - Technical architecture (NEW)

### Baseline (v1.0 - Still Valid)
- [ARCHITECTURE_LOCAL_REMOTE_MODEL_SYSTEM.md](ARCHITECTURE_LOCAL_REMOTE_MODEL_SYSTEM.md) - Local + Ollama architecture
- [PRODUCT_REQUIREMENTS.md](PRODUCT_REQUIREMENTS.md) - v1.0 MVP requirements

### Future Planning (v2.0)
- [PRODUCT_ROADMAP_V2.md](PRODUCT_ROADMAP_V2.md) - Tool calling, comparison, etc.
- [REQUIREMENTS_V2.md](REQUIREMENTS_V2.md) - Advanced features

---

## üóÇÔ∏è Documentation Status

### ‚úÖ Updated for v1.5
- PRODUCT_VISION.md
- This file (STRATEGIC_REFOCUS_V1.5.md)

### üÜï Created for v1.5
- PRODUCT_REQUIREMENTS_V1.5.md
- ARCHITECTURE_CLOUD_API_INTEGRATION.md

### üîÑ Needs Updating
- USER_PERSONAS.md - Add cloud-focused personas
- ARCHITECTURE_DECISIONS.md - Document provider abstraction decision
- UX_DESIGN_LOCAL_REMOTE_MODEL_SYSTEM.md - Extend to include cloud providers

### ‚ö†Ô∏è Potentially Obsolete
Some v2 planning docs may conflict with v1.5. Prioritize v1.5 documents.

---

## üõ†Ô∏è Implementation Priorities

### Phase 1: Provider Abstraction (Weeks 1-2)
**Priority:** P0 - Foundation

- [ ] Create `LLMProvider` interface
- [ ] Refactor Ollama ‚Üí `OllamaProvider`
- [ ] Refactor LiteRT ‚Üí `LocalProvider`
- [ ] Create `ProviderRegistry`
- [ ] Update `ChatService` to use providers

### Phase 2: Cloud API Integration (Weeks 3-4)
**Priority:** P0 - Core Feature

- [ ] Implement `OpenAIProvider` with streaming
- [ ] Implement `AnthropicProvider` with streaming
- [ ] Implement `GoogleAIProvider` with streaming
- [ ] Add secure API key storage
- [ ] Implement token usage tracking

### Phase 3: UX & Cost Tracking (Weeks 5-6)
**Priority:** P0 - User Value

- [ ] Update model picker (unified list with badges)
- [ ] Add provider settings screen
- [ ] Display token usage and costs
- [ ] Implement smart fallback logic
- [ ] Add cost limits and warnings

### Phase 4: Polish & Release (Week 7)
**Priority:** P0 - Quality

- [ ] Comprehensive error handling
- [ ] Performance optimizations
- [ ] User documentation
- [ ] Beta testing
- [ ] Bug fixes and release

---

## üö® Critical Don'ts

### ‚ùå Don't Do This:
- Hardcode provider-specific logic in `ChatService`
- Assume all models are free (track costs for cloud)
- Forget offline support for cloud APIs (queue messages)
- Expose API keys in logs or UI
- Add new providers without implementing full interface

### ‚úÖ Do This Instead:
- Use `LLMProvider` abstraction for all backends
- Track token usage and costs for cloud APIs
- Queue cloud API messages when offline
- Store API keys securely (flutter_secure_storage)
- Implement full provider interface for new backends

---

## üí° Key Design Decisions

### 1. **Why Support Cloud APIs?**
- **Market Expansion**: Reach users who want convenience + privacy
- **Differentiation**: Only mobile app supporting local + cloud + self-hosted
- **User Flexibility**: Let users choose their privacy/cost balance
- **Competitive Advantage**: ChatGPT app = cloud only, Jan.ai = local only, we = **both**

### 2. **Why Provider Abstraction?**
- **Extensibility**: Easy to add new providers (Mistral, Cohere, Groq, etc.)
- **Consistency**: Unified UX regardless of backend
- **Testing**: Easy to mock providers for tests
- **Maintainability**: Provider changes don't affect core logic

### 3. **Why Cost Tracking?**
- **Transparency**: Users should know what they're spending
- **Trust**: No hidden costs or surprises
- **Value**: Help users optimize costs (suggest local/Ollama alternatives)
- **Future Monetization**: Enable pro features (cost optimization, analytics)

### 4. **Why Smart Fallbacks?**
- **Reliability**: Always try to deliver value to user
- **Flexibility**: Adapt to changing conditions (API down, offline, etc.)
- **User Control**: Let users configure fallback preferences
- **Seamless**: Minimize user interruption

---

## üîç Quick Reference for Agents

### When Implementing New Features:

**Ask Yourself:**
1. Does this work for **all provider types**?
2. Do I need to track **costs** (for cloud APIs)?
3. Does the **UI** clearly show provider/cost info?
4. Is **error handling** comprehensive?
5. Does **fallback logic** make sense?

**Use These Patterns:**
```dart
// Get provider from registry
final provider = providerRegistry.getProvider(providerId);

// Send message via provider
await for (final response in provider.sendMessage(...)) {
  // Handle streaming response
}

// Track costs (cloud APIs only)
if (provider.type == ProviderType.CLOUD_API) {
  await costTracker.recordUsage(...);
}

// Handle errors with fallbacks
try {
  // ... send message
} on LLMProviderException catch (e) {
  if (e.suggestedFallback != null) {
    // Try fallback
  }
}
```

---

## üìû Questions? Start Here:

### Product Questions
- **Vision/Strategy**: See [PRODUCT_VISION.md](PRODUCT_VISION.md)
- **Requirements**: See [PRODUCT_REQUIREMENTS_V1.5.md](PRODUCT_REQUIREMENTS_V1.5.md)
- **Use Cases**: See USER_STORIES_V1.5.md (to be created)

### Technical Questions
- **Architecture**: See [ARCHITECTURE_CLOUD_API_INTEGRATION.md](ARCHITECTURE_CLOUD_API_INTEGRATION.md)
- **Implementation**: See ARCHITECTURE_CLOUD_API_INTEGRATION.md (Migration Path section)
- **Testing**: See ARCHITECTURE_CLOUD_API_INTEGRATION.md (Testing Strategy section)

### UX Questions
- **Design**: See UX_DESIGN_CLOUD_API.md (to be created)
- **User Flows**: See UX_DESIGN_CLOUD_API.md (to be created)

---

## ‚úÖ Next Steps for Agents

### @architect
1. Review [ARCHITECTURE_CLOUD_API_INTEGRATION.md](ARCHITECTURE_CLOUD_API_INTEGRATION.md)
2. Validate provider abstraction design
3. Create proof-of-concept for OpenAI provider
4. Update ARCHITECTURE_DECISIONS.md with cloud API rationale

### @flutter-developer
1. Begin Phase 1: Provider abstraction refactor
2. Create `LLMProvider` interface
3. Refactor existing Ollama/LiteRT code
4. Implement provider registry

### @experience-designer
1. Create UX_DESIGN_CLOUD_API.md
2. Design unified model picker UI
3. Design cost display patterns
4. Create fallback dialog mockups

### @doc-writer
1. Update USER_PERSONAS.md with cloud users
2. Create USER_STORIES_V1.5.md
3. Update README.md with new vision
4. Create setup guides for cloud APIs

### @researcher
1. Research OpenAI/Anthropic/Google AI APIs
2. Compare pricing models across providers
3. Investigate rate limiting and quotas
4. Find best practices for API key management

---

## üìä Success Criteria

### Technical
- [ ] All 5 providers work (Local, Ollama, OpenAI, Anthropic, Google)
- [ ] Streaming works consistently across all providers
- [ ] Fallback chains execute correctly
- [ ] Cost tracking accurate within 5%
- [ ] No API keys exposed in logs/crashes

### User Experience
- [ ] Model picker shows all models clearly
- [ ] Provider status always visible
- [ ] Cost displayed for all cloud messages
- [ ] Fallbacks happen seamlessly (or with clear prompts)
- [ ] Setup is intuitive (< 5 min per provider)

### Business
- [ ] 60%+ users configure at least one cloud API
- [ ] App Store rating maintained (4.5+)
- [ ] Positive feedback on flexibility
- [ ] No major security incidents

---

**Last Updated:** January 26, 2026  
**Maintained By:** @product-owner

**For Questions:** Reference this document in your agent prompt context.
